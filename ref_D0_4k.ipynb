{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd2fb963",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_check_weights' from 'sklearn.neighbors._base' (C:\\Users\\Ivan\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1864\\3575622706.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sklearn.neighbors.base'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmissingpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMissForest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\missingpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mknnimpute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNNImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmissforest\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMissForest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'KNNImputer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MissForest'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\missingpy\\knnimpute.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_check_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_check_weights' from 'sklearn.neighbors._base' (C:\\Users\\Ivan\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py)"
     ]
    }
   ],
   "source": [
    "# Tensorflow / Keras\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Dense # for creating regular densely-connected NN layers.\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "import numpy as np # for data manipulation\n",
    "\n",
    "# Sklearn\n",
    "import sklearn # for model evaluation\n",
    "from sklearn.model_selection import train_test_split # for splitting data into train and test samples\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Erstellung eigener Aktivierungsfunktion\n",
    "from keras import backend as K\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "import sys\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn==1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f090d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Inter op parallelism cannot be modified after initialization.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2932\\92949941.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TF_NUM_INTRAOP_THREADS'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_inter_op_parallelism_threads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_intra_op_parallelism_threads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\config.py\u001b[0m in \u001b[0;36mset_inter_op_parallelism_threads\u001b[1;34m(num_threads)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mnum_threads\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparallel\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m   \"\"\"\n\u001b[1;32m--> 144\u001b[1;33m   \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minter_op_parallelism_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36minter_op_parallelism_threads\u001b[1;34m(self, num_threads)\u001b[0m\n\u001b[0;32m   1837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m       raise RuntimeError(\n\u001b[0m\u001b[0;32m   1840\u001b[0m           \"Inter op parallelism cannot be modified after initialization.\")\n\u001b[0;32m   1841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Inter op parallelism cannot be modified after initialization."
     ]
    }
   ],
   "source": [
    "desired_cpu_usage = 0.90\n",
    "num_threads = int(os.cpu_count() * desired_cpu_usage)\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = str(num_threads)\n",
    "os.environ['TF_NUM_INTEROP_THREADS'] = str(num_threads)\n",
    "os.environ['TF_NUM_INTRAOP_THREADS'] = str(num_threads)\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(num_threads)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6390e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.raw_data = None\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.new_df = None\n",
    "        self.data_inpute = None\n",
    "        self.result = None\n",
    "\n",
    "    def import_data(self, sample_size = 11500):\n",
    "        csv_files = []\n",
    "        for filename in os.listdir():\n",
    "            if filename == \"Datasets\":\n",
    "                for csv_file in os.listdir(filename):\n",
    "                    if csv_file.endswith('.csv'):\n",
    "                        csv_files.append(csv_file)\n",
    "\n",
    "        self.raw_data = pd.read_csv(os.path.join(\"Datasets\", csv_files[0]))\n",
    "        self.raw_data.drop([\"Time\"], axis=1, inplace=True)\n",
    "        self.raw_data.drop([\"Amount\"], axis=1, inplace=True)\n",
    "        \n",
    "        # Auswahl von 4000 zufälligen Zeilen\n",
    "        self.raw_data = self.raw_data.sample(n=sample_size, random_state=42)        \n",
    "        \n",
    "        self.Y = self.raw_data[\"Class\"]\n",
    "        self.X = self.raw_data.drop([\"Class\"], axis=1)\n",
    "        return self.raw_data, self.Y, self.X\n",
    "\n",
    "    def gen_miss_values(self, p):\n",
    "        # Auswahl von 35% zufälligen Zeilen aus X\n",
    "        sample_percentage = 0.35\n",
    "        sampled_rows = int(self.X.shape[0] * sample_percentage)\n",
    "        sampled_X = self.X.sample(n=sampled_rows, random_state=42)\n",
    "        shape = sampled_X.shape\n",
    "        \n",
    "        self.new_df = sampled_X.copy().astype(np.float64)\n",
    "        missing = np.random.binomial(1, p, shape)\n",
    "        self.new_df[missing.astype('bool')] = np.nan\n",
    "        return self.new_df\n",
    "\n",
    "    \n",
    "    def print_progress(self, model, progress):\n",
    "        print(f\"Imputing {model} model: {progress * 100:.2f}% completed\")\n",
    "    \n",
    "    def inpute_data(self, model):\n",
    "        if model == \"mean\":\n",
    "            self.data_inpute = self.new_df.fillna(self.new_df.mean())\n",
    "            self.data_inpute = pd.concat([self.data_inpute, self.Y], axis=1, sort=False)\n",
    "            columns = self.data_inpute.columns.tolist()\n",
    "\n",
    "            for i in range(len(columns) - 1):\n",
    "                columns[i] = \"col_\" + str(i + 1)\n",
    "            self.data_inpute.columns = columns\n",
    "            self.data_inpute.columns = [*self.data_inpute.columns[:-1], 'Y']\n",
    "            \n",
    "            self.Y = self.data_inpute[\"Y\"]\n",
    "            self.X = self.data_inpute.drop([\"Y\"], axis=1)\n",
    "            return self.data_inpute\n",
    "\n",
    "        elif model == \"MICE\":\n",
    "            imputer = IterativeImputer()\n",
    "            self.data_inpute = pd.DataFrame(imputer.fit_transform(self.new_df), columns=self.new_df.columns)\n",
    "            self.data_inpute = pd.concat([self.data_inpute, self.Y], axis=1, sort=False)\n",
    "\n",
    "            columns = self.data_inpute.columns.tolist()\n",
    "\n",
    "            for i in range(len(columns) - 1):\n",
    "                columns[i] = \"col_\" + str(i + 1)\n",
    "            self.data_inpute.columns = columns\n",
    "            self.data_inpute.columns = [*self.data_inpute.columns[:-1], 'Y']\n",
    "\n",
    "            self.Y = self.data_inpute[\"Y\"]\n",
    "            self.X = self.data_inpute.drop([\"Y\"], axis=1)\n",
    "\n",
    "            return self.data_inpute, self.raw_data[\"Class\"]\n",
    "\n",
    "        elif model == \"kNN\":\n",
    "            imputer = KNNImputer()\n",
    "            self.data_inpute = pd.DataFrame(imputer.fit_transform(self.new_df), columns=self.new_df.columns)\n",
    "            self.data_inpute = pd.concat([self.data_inpute, self.Y], axis=1, sort=False)\n",
    "\n",
    "            columns = self.data_inpute.columns.tolist()\n",
    "\n",
    "            for i in range(len(columns) - 1):\n",
    "                columns[i] = \"col_\" + str(i + 1)\n",
    "            self.data_inpute.columns = columns\n",
    "            self.data_inpute.columns = [*self.data_inpute.columns[:-1], 'Y']\n",
    "\n",
    "            self.Y = self.data_inpute[\"Y\"]\n",
    "            self.X = self.data_inpute.drop([\"Y\"], axis=1)\n",
    "            \n",
    "            return self.data_inpute, self.raw_data[\"Class\"]\n",
    "        \n",
    "        elif model == \"RF\":\n",
    "            imputer = MissForest(max_iter=5, random_state=42, n_jobs=-1, criterion='squared_error')\n",
    "            self.data_inpute = pd.DataFrame(imputer.fit_transform(self.new_df), columns=self.new_df.columns)\n",
    "            self.data_inpute = pd.concat([self.data_inpute, self.Y], axis=1, sort=False)\n",
    "\n",
    "            columns = self.data_inpute.columns.tolist()\n",
    "\n",
    "            for i in range(len(columns) - 1):\n",
    "                columns[i] = \"col_\" + str(i + 1)\n",
    "            self.data_inpute.columns = columns\n",
    "            self.data_inpute.columns = [*self.data_inpute.columns[:-1], 'Y']\n",
    "\n",
    "            self.Y = self.data_inpute[\"Y\"]\n",
    "            self.X = self.data_inpute.drop([\"Y\"], axis=1)\n",
    "\n",
    "            return self.data_inpute, self.raw_data[\"Class\"]\n",
    "    \n",
    "    def model(self, model):\n",
    "        if model == 0:\n",
    "            return load_model(\"model_D0_01.h5\")\n",
    "        elif model == 1:\n",
    "            return load_model(\"model_D0_02.h5\")\n",
    "        elif model == 2:\n",
    "            return load_model(\"model_D0_03.h5\")\n",
    "\n",
    "    def evaluate(self, y_test, y_nan):\n",
    "        y_true = y_test\n",
    "        y_pred = y_nan\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        # Compute the accuracy\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        # Compute the precision\n",
    "        precision_scores = precision_score(y_true, y_pred, labels=range(len(conf_matrix)), average=None)\n",
    "\n",
    "        # Compute the recall\n",
    "        recall = recall_score(y_true, y_pred, labels=range(len(conf_matrix)), average=None)\n",
    "\n",
    "        # Compute the F1-score\n",
    "        f1 = f1_score(y_true, y_pred, labels=range(len(conf_matrix)), average=None)\n",
    "\n",
    "        # Compute the average accuracy\n",
    "        avg_accuracy = sum(precision_scores) / len(conf_matrix)\n",
    "\n",
    "        # Compute the predicted probabilities\n",
    "        y_scores = np.random.rand(len(y_true), len(np.unique(y_true)))\n",
    "\n",
    "        ## Compute the AUC for each class\n",
    "        n_classes = conf_matrix.shape[0]\n",
    "        auc_list = []\n",
    "        for i in range(n_classes):\n",
    "            auc_list.append(roc_auc_score(y_true == i, y_scores[:, i]))\n",
    "\n",
    "        # Define the result dictionary\n",
    "        self.result = {\n",
    "            \"confusion_matrix\": conf_matrix,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision_scores,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "            \"avg_accuracy\": avg_accuracy,\n",
    "            \"auc\": auc_list\n",
    "        }\n",
    "        return self.result\n",
    "    def save_txt(self, filename, evaluate):\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(str(evaluate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aee94c9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[2232, 1212],\n",
      "       [   4,    2]], dtype=int64), 'accuracy': 0.647536231884058, 'precision': array([0.99821109, 0.00164745]), 'recall': array([0.64808362, 0.33333333]), 'f1_score': array([0.78591549, 0.00327869]), 'avg_accuracy': 0.49992926884616856, 'auc': [0.4143921796360821, 0.49172473867595823]}\n",
      "108/108 [==============================] - 0s 3ms/step\n",
      "{'confusion_matrix': array([[2231, 1213],\n",
      "       [   3,    3]], dtype=int64), 'accuracy': 0.647536231884058, 'precision': array([0.99865712, 0.00246711]), 'recall': array([0.64779326, 0.5       ]), 'f1_score': array([0.78584008, 0.00490998]), 'avg_accuracy': 0.5005621112707911, 'auc': [0.3512388695315524, 0.47706155632984903]}\n",
      "108/108 [==============================] - 0s 3ms/step\n",
      "{'confusion_matrix': array([[2231, 1216],\n",
      "       [   3,    0]], dtype=int64), 'accuracy': 0.6466666666666666, 'precision': array([0.99865712, 0.        ]), 'recall': array([0.64722947, 0.        ]), 'f1_score': array([0.7854251, 0.       ]), 'avg_accuracy': 0.49932855863921216, 'auc': [0.6461657479934243, 0.5854366115462721]}\n",
      "108/108 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[2230, 1215],\n",
      "       [   4,    1]], dtype=int64), 'accuracy': 0.6466666666666666, 'precision': array([9.98209490e-01, 8.22368421e-04]), 'recall': array([0.64731495, 0.2       ]), 'f1_score': array([0.78534953, 0.001638  ]), 'avg_accuracy': 0.4995159290628092, 'auc': [0.4296081277213352, 0.5402031930333817]}\n",
      "108/108 [==============================] - 0s 3ms/step\n",
      "{'confusion_matrix': array([[2231, 1214],\n",
      "       [   3,    2]], dtype=int64), 'accuracy': 0.6472463768115942, 'precision': array([0.99865712, 0.00164474]), 'recall': array([0.64760522, 0.4       ]), 'f1_score': array([0.78570171, 0.003276  ]), 'avg_accuracy': 0.5001509270602648, 'auc': [0.48568940493468793, 0.5201741654571843]}\n",
      "108/108 [==============================] - 0s 3ms/step\n",
      "{'confusion_matrix': array([[2229, 1215],\n",
      "       [   5,    1]], dtype=int64), 'accuracy': 0.6463768115942029, 'precision': array([9.97761862e-01, 8.22368421e-04]), 'recall': array([0.64721254, 0.16666667]), 'f1_score': array([0.78513561, 0.00163666]), 'avg_accuracy': 0.49929211527587997, 'auc': [0.41289198606271776, 0.5954800619434766]}\n",
      "108/108 [==============================] - 1s 5ms/step\n",
      "{'confusion_matrix': array([[2231, 1215],\n",
      "       [   3,    1]], dtype=int64), 'accuracy': 0.6469565217391304, 'precision': array([9.98657117e-01, 8.22368421e-04]), 'recall': array([0.6474173, 0.25     ]), 'f1_score': array([0.78556338, 0.00163934]), 'avg_accuracy': 0.4997397428497385, 'auc': [0.3659315147997678, 0.577771329077191]}\n",
      "108/108 [==============================] - 1s 5ms/step\n",
      "{'confusion_matrix': array([[2232, 1215],\n",
      "       [   2,    1]], dtype=int64), 'accuracy': 0.6472463768115942, 'precision': array([9.99104745e-01, 8.22368421e-04]), 'recall': array([0.64751958, 0.33333333]), 'f1_score': array([0.78577715, 0.00164069]), 'avg_accuracy': 0.4999635566366678, 'auc': [0.6547722657383233, 0.7447055410501885]}\n",
      "108/108 [==============================] - 1s 5ms/step\n",
      "{'confusion_matrix': array([[2228, 1214],\n",
      "       [   6,    2]], dtype=int64), 'accuracy': 0.6463768115942029, 'precision': array([0.99731423, 0.00164474]), 'recall': array([0.64729808, 0.25      ]), 'f1_score': array([0.7850599 , 0.00326797]), 'avg_accuracy': 0.49947948569947703, 'auc': [0.4401147588611273, 0.6495859965136548]}\n"
     ]
    }
   ],
   "source": [
    "data_processor = DataProcessor()\n",
    "load_data = data_processor.import_data()\n",
    "test_size = 0.3  # Konstante Testgröße\n",
    "\n",
    "for model_number in range(0, 3):  # Modelle 1-3 durchlaufen\n",
    "    model_name = f\"Model_{model_number + 1}\"\n",
    "    output_prefix = f\"prediction_ref_mean_D0_{model_name}_\"\n",
    "    model = data_processor.model(model_number)\n",
    "    \n",
    "    for missing_rate in [0.3, 0.6, 0.9]:\n",
    "        miss_data = data_processor.gen_miss_values(missing_rate)\n",
    "        inpute_values = data_processor.inpute_data(\"mean\")\n",
    "        \n",
    "        comparison_col = [1 if x == y else 0 for x, y in zip(inpute_values[\"Y\"], load_data[0][\"Class\"])]\n",
    "        df = pd.DataFrame({\"Y\": inpute_values[\"Y\"], \"Class\": load_data[0][\"Class\"], \"Comparison\": comparison_col})\n",
    "        \n",
    "        Y = inpute_values[\"Y\"]\n",
    "        X = inpute_values.drop([\"Y\"], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        df = pd.DataFrame(y_pred, index=X_test.index)\n",
    "        df['larger_value'] = df.apply(lambda row: 1 if row[0] > row[1] else 0 if row[0] < row[1] else 0.5, axis=1)\n",
    "        y_pred = df[\"larger_value\"]\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "        result[\"y_pred\"] = y_pred\n",
    "        result[\"y_test\"] = y_test[X_test.index].values\n",
    "        threshold = 0.5\n",
    "        y_pred_binary = np.where(result['y_pred'] > threshold, 1, 0)\n",
    "        y_test_binary = np.where(result['y_test'] > threshold, 1, 0)\n",
    "        evaluate = data_processor.evaluate(y_test_binary, y_pred_binary)\n",
    "        print(evaluate)\n",
    "        filename = output_prefix + str(missing_rate).replace(\".\", \"_\")\n",
    "        data_processor.save_txt(filename, evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23c33b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3399, 1202],\n",
      "       [   7,    0]], dtype=int64), 'accuracy': 0.7376302083333334, 'precision': array([0.9979448, 0.       ]), 'recall': array([0.73875245, 0.        ]), 'f1_score': array([0.84900712, 0.        ]), 'avg_accuracy': 0.49897240164415735, 'auc': [0.536529325922936, 0.391653988263421]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3367, 1628],\n",
      "       [   6,    0]], dtype=int64), 'accuracy': 0.6732653469306139, 'precision': array([0.99822117, 0.        ]), 'recall': array([0.67407407, 0.        ]), 'f1_score': array([0.80473231, 0.        ]), 'avg_accuracy': 0.4991105840498073, 'auc': [0.6575575575575575, 0.6271271271271271]}\n",
      "161/161 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3391, 1737],\n",
      "       [   6,    0]], dtype=int64), 'accuracy': 0.660498636540709, 'precision': array([0.99823374, 0.        ]), 'recall': array([0.66127145, 0.        ]), 'f1_score': array([0.79554252, 0.        ]), 'avg_accuracy': 0.49911686782455106, 'auc': [0.32543551742069676, 0.4360374414976599]}\n",
      "162/162 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3390, 1784],\n",
      "       [   4,    0]], dtype=int64), 'accuracy': 0.6546929316338355, 'precision': array([0.99882145, 0.        ]), 'recall': array([0.65519907, 0.        ]), 'f1_score': array([0.79131653, 0.        ]), 'avg_accuracy': 0.4994107248084856, 'auc': [0.47313490529570934, 0.311654425976034]}\n",
      "163/163 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3382, 1803],\n",
      "       [   9,    0]], dtype=int64), 'accuracy': 0.6511359260685406, 'precision': array([0.99734592, 0.        ]), 'recall': array([0.65226615, 0.        ]), 'f1_score': array([0.78871269, 0.        ]), 'avg_accuracy': 0.4986729578295488, 'auc': [0.3920282867245259, 0.5986713811207542]}\n",
      "  1/163 [..............................] - ETA: 4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 3ms/step\n",
      "{'confusion_matrix': array([[3388, 1804],\n",
      "       [   7,    0]], dtype=int64), 'accuracy': 0.6516637814964417, 'precision': array([0.99793814, 0.        ]), 'recall': array([0.65254237, 0.        ]), 'f1_score': array([0.7890998, 0.       ]), 'avg_accuracy': 0.49896907216494846, 'auc': [0.5684569667620516, 0.5149405679066696]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1s 5ms/step\n",
      "{'confusion_matrix': array([[3386, 1808],\n",
      "       [   7,    0]], dtype=int64), 'accuracy': 0.6510286483368583, 'precision': array([0.99793693, 0.        ]), 'recall': array([0.65190605, 0.        ]), 'f1_score': array([0.78863398, 0.        ]), 'avg_accuracy': 0.49896846448570586, 'auc': [0.3931459376203312, 0.4449089608889378]}\n",
      "  1/163 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1s 4ms/step\n",
      "{'confusion_matrix': array([[3394, 1800],\n",
      "       [   8,    0]], dtype=int64), 'accuracy': 0.6524413687043444, 'precision': array([0.99764844, 0.        ]), 'recall': array([0.65344628, 0.        ]), 'f1_score': array([0.78966961, 0.        ]), 'avg_accuracy': 0.49882422104644325, 'auc': [0.7168608009241433, 0.5336927223719676]}\n",
      "  1/163 [..............................] - ETA: 9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1s 4ms/step\n",
      "{'confusion_matrix': array([[3393, 1803],\n",
      "       [   6,    0]], dtype=int64), 'accuracy': 0.6522491349480969, 'precision': array([0.99823477, 0.        ]), 'recall': array([0.65300231, 0.        ]), 'f1_score': array([0.7895288, 0.       ]), 'avg_accuracy': 0.49911738746690204, 'auc': [0.5030792917628946, 0.6684629201950218]}\n"
     ]
    }
   ],
   "source": [
    "data_processor = DataProcessor()\n",
    "load_data = data_processor.import_data()\n",
    "test_size = 0.3  # Konstante Testgröße\n",
    "\n",
    "for model_number in range(0, 3):  # Modelle 1-3 durchlaufen\n",
    "    model_name = f\"Model_{model_number + 1}\"\n",
    "    output_prefix = f\"prediction_ref_MICE_D0_{model_name}_\"\n",
    "    model = data_processor.model(model_number)\n",
    "    \n",
    "    for missing_rate in [0.3, 0.6, 0.9]:\n",
    "        miss_data = data_processor.gen_miss_values(missing_rate)\n",
    "        inpute_values, class_values = data_processor.inpute_data(\"MICE\")\n",
    "        \n",
    "        # Reset indices\n",
    "        inpute_values_y = inpute_values[\"Y\"].reset_index(drop=True)\n",
    "        class_values = class_values.reset_index(drop=True)\n",
    "\n",
    "        # Reduce the length of inpute_values_y and class_values to the same length\n",
    "        min_length = min(len(inpute_values_y), len(class_values))\n",
    "        inpute_values_y = inpute_values_y[:min_length]\n",
    "        class_values = class_values[:min_length]\n",
    "\n",
    "        comparison_col = [1 if x == y else 0 for x, y in zip(inpute_values_y, class_values)]\n",
    "        df = pd.DataFrame({\"Y\": inpute_values_y, \"Class\": class_values, \"Comparison\": comparison_col})\n",
    "        Y = inpute_values[\"Y\"]\n",
    "        X = inpute_values.drop([\"Y\"], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        df = pd.DataFrame(y_pred, index=X_test.index)\n",
    "        df['larger_value'] = df.apply(lambda row: 1 if row[0] > row[1] else 0 if row[0] < row[1] else 0.5, axis=1)\n",
    "        y_pred = df[\"larger_value\"]\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "        result[\"y_pred\"] = y_pred\n",
    "        result[\"y_test\"] = y_test[X_test.index].values\n",
    "        threshold = 0.5\n",
    "        y_pred_binary = np.where(result['y_pred'] > threshold, 1, 0)\n",
    "        y_test_binary = np.where(result['y_test'] > threshold, 1, 0)\n",
    "        evaluate = data_processor.evaluate(y_test_binary, y_pred_binary)\n",
    "        print(evaluate)\n",
    "        filename = output_prefix + str(missing_rate).replace(\".\", \"_\")\n",
    "        data_processor.save_txt(filename, evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c03f0d78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3398, 1203],\n",
      "       [   7,    0]], dtype=int64), 'accuracy': 0.7374131944444444, 'precision': array([0.9979442, 0.       ]), 'recall': array([0.7385351, 0.       ]), 'f1_score': array([0.84886335, 0.        ]), 'avg_accuracy': 0.4989720998531571, 'auc': [0.45114416120719103, 0.45803707268606203]}\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3367, 1628],\n",
      "       [   6,    0]], dtype=int64), 'accuracy': 0.6732653469306139, 'precision': array([0.99822117, 0.        ]), 'recall': array([0.67407407, 0.        ]), 'f1_score': array([0.80473231, 0.        ]), 'avg_accuracy': 0.4991105840498073, 'auc': [0.5579245912579246, 0.35722389055722387]}\n",
      "161/161 [==============================] - 0s 3ms/step\n",
      "{'confusion_matrix': array([[3391, 1737],\n",
      "       [   6,    0]], dtype=int64), 'accuracy': 0.660498636540709, 'precision': array([0.99823374, 0.        ]), 'recall': array([0.66127145, 0.        ]), 'f1_score': array([0.79554252, 0.        ]), 'avg_accuracy': 0.49911686782455106, 'auc': [0.6593213728549142, 0.5337688507540301]}\n",
      "162/162 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3390, 1784],\n",
      "       [   4,    0]], dtype=int64), 'accuracy': 0.6546929316338355, 'precision': array([0.99882145, 0.        ]), 'recall': array([0.65519907, 0.        ]), 'f1_score': array([0.79131653, 0.        ]), 'avg_accuracy': 0.4994107248084856, 'auc': [0.6285755701584848, 0.47105720912253574]}\n",
      "163/163 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3382, 1803],\n",
      "       [   9,    0]], dtype=int64), 'accuracy': 0.6511359260685406, 'precision': array([0.99734592, 0.        ]), 'recall': array([0.65226615, 0.        ]), 'f1_score': array([0.78871269, 0.        ]), 'avg_accuracy': 0.4986729578295488, 'auc': [0.26385942355084113, 0.4380585020893603]}\n",
      "163/163 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3388, 1804],\n",
      "       [   7,    0]], dtype=int64), 'accuracy': 0.6516637814964417, 'precision': array([0.99793814, 0.        ]), 'recall': array([0.65254237, 0.        ]), 'f1_score': array([0.7890998, 0.       ]), 'avg_accuracy': 0.49896907216494846, 'auc': [0.5025588817961699, 0.46585406119304423]}\n",
      "163/163 [==============================] - 1s 5ms/step\n",
      "{'confusion_matrix': array([[3386, 1808],\n",
      "       [   7,    0]], dtype=int64), 'accuracy': 0.6510286483368583, 'precision': array([0.99793693, 0.        ]), 'recall': array([0.65190605, 0.        ]), 'f1_score': array([0.78863398, 0.        ]), 'avg_accuracy': 0.49896846448570586, 'auc': [0.4498322239947192, 0.41523186093844544]}\n",
      "163/163 [==============================] - 1s 5ms/step\n",
      "{'confusion_matrix': array([[3394, 1800],\n",
      "       [   8,    0]], dtype=int64), 'accuracy': 0.6524413687043444, 'precision': array([0.99764844, 0.        ]), 'recall': array([0.65344628, 0.        ]), 'f1_score': array([0.78966961, 0.        ]), 'avg_accuracy': 0.49882422104644325, 'auc': [0.4291008856372738, 0.6668030419715056]}\n",
      "163/163 [==============================] - 1s 5ms/step\n",
      "{'confusion_matrix': array([[3393, 1803],\n",
      "       [   6,    0]], dtype=int64), 'accuracy': 0.6522491349480969, 'precision': array([0.99823477, 0.        ]), 'recall': array([0.65300231, 0.        ]), 'f1_score': array([0.7895288, 0.       ]), 'avg_accuracy': 0.49911738746690204, 'auc': [0.43324993584808824, 0.43876700025660764]}\n"
     ]
    }
   ],
   "source": [
    "data_processor = DataProcessor()\n",
    "load_data = data_processor.import_data()\n",
    "test_size = 0.3  # Konstante Testgröße\n",
    "\n",
    "for model_number in range(0, 3):  # Modelle 1-3 durchlaufen\n",
    "    model_name = f\"Model_{model_number + 1}\"\n",
    "    output_prefix = f\"prediction_ref_kNN_D0_{model_name}_\"\n",
    "    model = data_processor.model(model_number)\n",
    "    \n",
    "    for missing_rate in [0.3, 0.6, 0.9]:\n",
    "        miss_data = data_processor.gen_miss_values(missing_rate)\n",
    "        inpute_values, class_values = data_processor.inpute_data(\"kNN\")\n",
    "        \n",
    "        # Reset indices\n",
    "        inpute_values_y = inpute_values[\"Y\"].reset_index(drop=True)\n",
    "        class_values = class_values.reset_index(drop=True)\n",
    "\n",
    "        # Reduce the length of inpute_values_y and class_values to the same length\n",
    "        min_length = min(len(inpute_values_y), len(class_values))\n",
    "        inpute_values_y = inpute_values_y[:min_length]\n",
    "        class_values = class_values[:min_length]\n",
    "\n",
    "        comparison_col = [1 if x == y else 0 for x, y in zip(inpute_values_y, class_values)]\n",
    "        df = pd.DataFrame({\"Y\": inpute_values_y, \"Class\": class_values, \"Comparison\": comparison_col})\n",
    "        \n",
    "        Y = inpute_values[\"Y\"]\n",
    "        X = inpute_values.drop([\"Y\"], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        df = pd.DataFrame(y_pred, index=X_test.index)\n",
    "        df['larger_value'] = df.apply(lambda row: 1 if row[0] > row[1] else 0 if row[0] < row[1] else 0.5, axis=1)\n",
    "        y_pred = df[\"larger_value\"]\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "        result[\"y_pred\"] = y_pred\n",
    "        result[\"y_test\"] = y_test[X_test.index].values\n",
    "        threshold = 0.5\n",
    "        y_pred_binary = np.where(result['y_pred'] > threshold, 1, 0)\n",
    "        y_test_binary = np.where(result['y_test'] > threshold, 1, 0)\n",
    "        evaluate = data_processor.evaluate(y_test_binary, y_pred_binary)\n",
    "        print(evaluate)\n",
    "        filename = output_prefix + str(missing_rate).replace(\".\", \"_\")\n",
    "        data_processor.save_txt(filename, evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7260e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "144/144 [==============================] - 0s 2ms/step\n",
      "{'confusion_matrix': array([[3399, 1202],\n",
      "       [   7,    0]], dtype=int64), 'accuracy': 0.7376302083333334, 'precision': array([0.9979448, 0.       ]), 'recall': array([0.73875245, 0.        ]), 'f1_score': array([0.84900712, 0.        ]), 'avg_accuracy': 0.49897240164415735, 'auc': [0.37550842984444377, 0.5091129257614804]}\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3367, 1628],\n",
      "       [   6,    0]], dtype=int64), 'accuracy': 0.6732653469306139, 'precision': array([0.99822117, 0.        ]), 'recall': array([0.67407407, 0.        ]), 'f1_score': array([0.80473231, 0.        ]), 'avg_accuracy': 0.4991105840498073, 'auc': [0.5068401735068402, 0.6666332999666333]}\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "161/161 [==============================] - 0s 3ms/step\n",
      "{'confusion_matrix': array([[3391, 1737],\n",
      "       [   6,    0]], dtype=int64), 'accuracy': 0.660498636540709, 'precision': array([0.99823374, 0.        ]), 'recall': array([0.66127145, 0.        ]), 'f1_score': array([0.79554252, 0.        ]), 'avg_accuracy': 0.49911686782455106, 'auc': [0.5142680707228289, 0.34630135205408213]}\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "162/162 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3390, 1784],\n",
      "       [   4,    0]], dtype=int64), 'accuracy': 0.6546929316338355, 'precision': array([0.99882145, 0.        ]), 'recall': array([0.65519907, 0.        ]), 'f1_score': array([0.79131653, 0.        ]), 'avg_accuracy': 0.4994107248084856, 'auc': [0.5, 0.39273289524545807]}\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "163/163 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3382, 1803],\n",
      "       [   9,    0]], dtype=int64), 'accuracy': 0.6511359260685406, 'precision': array([0.99734592, 0.        ]), 'recall': array([0.65226615, 0.        ]), 'f1_score': array([0.78871269, 0.        ]), 'avg_accuracy': 0.4986729578295488, 'auc': [0.503953712632594, 0.560634308368156]}\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "163/163 [==============================] - 1s 3ms/step\n",
      "{'confusion_matrix': array([[3388, 1804],\n",
      "       [   7,    0]], dtype=int64), 'accuracy': 0.6516637814964417, 'precision': array([0.99793814, 0.        ]), 'recall': array([0.65254237, 0.        ]), 'f1_score': array([0.7890998, 0.       ]), 'avg_accuracy': 0.49896907216494846, 'auc': [0.5792152762491745, 0.36396654193264366]}\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "163/163 [==============================] - 1s 5ms/step\n",
      "{'confusion_matrix': array([[3386, 1808],\n",
      "       [   7,    0]], dtype=int64), 'accuracy': 0.6510286483368583, 'precision': array([0.99793693, 0.        ]), 'recall': array([0.65190605, 0.        ]), 'f1_score': array([0.78863398, 0.        ]), 'avg_accuracy': 0.49896846448570586, 'auc': [0.49301391715715936, 0.5091314153693822]}\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "163/163 [==============================] - 1s 5ms/step\n",
      "{'confusion_matrix': array([[3394, 1800],\n",
      "       [   8,    0]], dtype=int64), 'accuracy': 0.6524413687043444, 'precision': array([0.99764844, 0.        ]), 'recall': array([0.65344628, 0.        ]), 'f1_score': array([0.78966961, 0.        ]), 'avg_accuracy': 0.49882422104644325, 'auc': [0.635829803619561, 0.44351655756642283]}\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "163/163 [==============================] - 1s 5ms/step\n",
      "{'confusion_matrix': array([[3393, 1803],\n",
      "       [   6,    0]], dtype=int64), 'accuracy': 0.6522491349480969, 'precision': array([0.99823477, 0.        ]), 'recall': array([0.65300231, 0.        ]), 'f1_score': array([0.7895288, 0.       ]), 'avg_accuracy': 0.49911738746690204, 'auc': [0.7542019502181165, 0.5877918911983577]}\n"
     ]
    }
   ],
   "source": [
    "data_processor = DataProcessor()\n",
    "load_data = data_processor.import_data()\n",
    "test_size = 0.3  # Konstante Testgröße\n",
    "\n",
    "for model_number in range(0, 3):  # Modelle 1-3 durchlaufen\n",
    "    model_name = f\"Model_{model_number + 1}\"\n",
    "    output_prefix = f\"prediction_ref_RF_D0_{model_name}_\"\n",
    "    model = data_processor.model(model_number)\n",
    "    \n",
    "    for missing_rate in [0.3, 0.6, 0.9]:\n",
    "        miss_data = data_processor.gen_miss_values(missing_rate)\n",
    "        inpute_values, class_values = data_processor.inpute_data(\"RF\")\n",
    "        \n",
    "        # Reset indices\n",
    "        inpute_values_y = inpute_values[\"Y\"].reset_index(drop=True)\n",
    "        class_values = class_values.reset_index(drop=True)\n",
    "\n",
    "        # Reduce the length of inpute_values_y and class_values to the same length\n",
    "        min_length = min(len(inpute_values_y), len(class_values))\n",
    "        inpute_values_y = inpute_values_y[:min_length]\n",
    "        class_values = class_values[:min_length]\n",
    "\n",
    "        comparison_col = [1 if x == y else 0 for x, y in zip(inpute_values_y, class_values)]\n",
    "        df = pd.DataFrame({\"Y\": inpute_values_y, \"Class\": class_values, \"Comparison\": comparison_col})\n",
    "        \n",
    "        Y = inpute_values[\"Y\"]\n",
    "        X = inpute_values.drop([\"Y\"], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        df = pd.DataFrame(y_pred, index=X_test.index)\n",
    "        df['larger_value'] = df.apply(lambda row: 1 if row[0] > row[1] else 0 if row[0] < row[1] else 0.5, axis=1)\n",
    "        y_pred = df[\"larger_value\"]\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "        result[\"y_pred\"] = y_pred\n",
    "        result[\"y_test\"] = y_test[X_test.index].values\n",
    "        threshold = 0.5\n",
    "        y_pred_binary = np.where(result['y_pred'] > threshold, 1, 0)\n",
    "        y_test_binary = np.where(result['y_test'] > threshold, 1, 0)\n",
    "        evaluate = data_processor.evaluate(y_test_binary, y_pred_binary)\n",
    "        print(evaluate)\n",
    "        filename = output_prefix + str(missing_rate).replace(\".\", \"_\")\n",
    "        data_processor.save_txt(filename, evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388cd557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
